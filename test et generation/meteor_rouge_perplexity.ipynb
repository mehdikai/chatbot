{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6an8A7pZigTm",
        "outputId": "011aae41-eab8-4097-b56d-0f67f2bfedb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement meteor_score (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for meteor_score\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for meteor contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/meteor/meteor.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/bleu/bleu.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "METEOR score: 0.78\n",
            "ROUGE-1 score: 0.61\n",
            "ROUGE-2 score: 0.41\n",
            "ROUGE-L score: 0.61\n",
            "Perplexity: 70.61\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets transformers[sentencepiece]\n",
        "! pip install nltk rouge_score\n",
        "! pip install nltk meteor_score\n",
        "\n",
        "from datasets import load_metric\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import nltk\n",
        "\n",
        "# Initialize metrics\n",
        "meteor = load_metric(\"meteor\")\n",
        "rouge = load_metric(\"rouge\")\n",
        "bleu = load_metric(\"bleu\")\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Sample predictions and references\n",
        "\"\"\"What is the capital of palestine?\n",
        "    What is the capital of isreal?\n",
        "    do palestinian have the right to defend themselves from the israelis occupation?\n",
        "    To whom does the disputed land originally belong?\n",
        "    What is the current status of peace negotiations?\n",
        "    Can the genocide carried out by the occupation be described as inhumane?\n",
        "    do israelis occupation have any right in committing this genocide?\n",
        "    do palestinian people deserve to be free?\"\n",
        "    is there any way to avoid this painful genocide?\"\"\"\n",
        "    #the machine-generated text\n",
        "predictions = [\n",
        "    \"I really loved reading the Hunger Games\",\n",
        "    \"The movie was good but the book was better.\",\n",
        "    \"I like cats more than dogs.\",\n",
        "    \"The weather is beautiful today.\",\n",
        "    \"I'm going to the store to buy some groceries.\",\n",
        "    \"I'm feeling a bit tired today.\",\n",
        "    \"I'm excited for the weekend!\",\n",
        "    \"I'm looking forward to going on vacation.\",\n",
        "    \"I'm happy to see you!\",\n",
        "    \"I'm grateful for all the good things in my life.\"\n",
        "]\n",
        "#human-generated text\n",
        "references = [\n",
        "    \"I loved reading the Hunger Games.\",\n",
        "    \"The movie was great, but the book was even better.\",\n",
        "    \"Cats are my favorite animal.\",\n",
        "    \"The sun is shining and the sky is blue.\",\n",
        "    \"I'm going to the supermarket to buy some food.\",\n",
        "    \"I'm a bit sleepy today.\",\n",
        "    \"I can't wait for the weekend!\",\n",
        "    \"I'm so excited for our trip!\",\n",
        "    \"It's great to see you!\",\n",
        "    \"I'm thankful for all the good things in my life.\"\n",
        "]\n",
        "\n",
        "# Tokenize the predictions and references\n",
        "predictions = [[word for word in nltk.word_tokenize(sentence)] for sentence in predictions]\n",
        "references = [[word for word in nltk.word_tokenize(sentence)] for sentence in references]\n",
        "\n",
        "# Compute METEOR score\n",
        "meteor_score = meteor.compute(predictions=predictions, references=references)\n",
        "print(f\"METEOR score: {meteor_score['meteor']:.2f}\")\n",
        "\n",
        "# Compute ROUGE scores\n",
        "rouge_scores = rouge.compute(predictions=predictions, references=references)\n",
        "\n",
        "# Access the individual ROUGE scores\n",
        "rouge1_score = rouge_scores['rouge1'].mid.fmeasure\n",
        "rouge2_score = rouge_scores['rouge2'].mid.fmeasure\n",
        "rougeL_score = rouge_scores['rougeL'].mid.fmeasure\n",
        "\n",
        "print(f\"ROUGE-1 score: {rouge1_score:.2f}\")\n",
        "print(f\"ROUGE-2 score: {rouge2_score:.2f}\")\n",
        "print(f\"ROUGE-L score: {rougeL_score:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Compute Perplexity\n",
        "inputs = tokenizer(\"Hugging Face is a startup based in New York City and Paris\", return_tensors=\"pt\")\n",
        "loss = model(input_ids=inputs[\"input_ids\"], labels=inputs[\"input_ids\"]).loss\n",
        "ppl = torch.exp(loss)\n",
        "print(f\"Perplexity: {ppl.item():.2f}\")"
      ]
    }
  ]
}